# Face Recognition System with Mask Detection

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.8+-green.svg)
![TensorFlow](https://img.shields.io/badge/tensorflow-2.0+-orange.svg)

A comprehensive, production-ready face recognition system with **mask detection capabilities**. This project implements a complete end-to-end pipeline supporting three variants: **unmasked faces**, **masked faces**, and **mixed scenarios**.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [System Architecture](#system-architecture)
- [Pipeline Variants](#pipeline-variants)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Usage Guide](#usage-guide)
- [Project Structure](#project-structure)
- [Configuration Options](#configuration-options)
- [Model Components](#model-components)
- [Performance](#performance)
- [Contributing](#contributing)
- [License](#license)

---

## âœ¨ Features

### Core Capabilities

âœ… **Multi-Face Detection** - Detects multiple faces in a single image  
âœ… **Mask Detection** - Identifies whether individuals are wearing masks  
âœ… **Deep Learning Embeddings** - MobileNetV2-based feature extraction  
âœ… **Texture Analysis** - Local Binary Pattern (LBP) feature extraction  
âœ… **Robust Identification** - Cosine similarity matching with configurable thresholds  
âœ… **Flexible Preprocessing** - Background removal, image resizing, filtering  
âœ… **Batch Processing** - Efficient processing of multiple images  
âœ… **Model Persistence** - Save and load trained models  

### Preprocessing Options

- **Background Removal** - Deep learning-based background segmentation
- **Image Filtering** - Gaussian Blur or Median Filtering for noise reduction
- **Image Resizing** - Uniform dimension normalization (default: 256Ã—256)

### Face Detection Options

- **YOLO** (default) - Fast and accurate real-time detection
- **MTCNN** - High-quality face detection
- **MediaPipe** - Lightweight alternative

---

## ğŸ—ï¸ System Architecture

```
INPUT IMAGE
    â†“
[PREPROCESSING] â†’ Remove background, resize
    â†“
[FACE DETECTION] â†’ Detect faces and mask status (YOLO/MTCNN/MediaPipe)
    â†“
[OPTIONAL FILTERING] â†’ Gaussian or Median filtering
    â†“
[FEATURE EXTRACTION]
    â”œâ”€â†’ LBP Extractor (texture features)
    â””â”€â†’ MobileNetV2 Embedder (deep features)
    â†“
[PERSON IDENTIFICATION] â†’ Cosine Similarity (threshold: 0.55)
    â†“
OUTPUT â†’ Person name + Confidence + Mask status
```

---

## ğŸ¯ Pipeline Variants

### 1. **Unmasked Pipeline** (`mobilenet_lbp_unmasked/`)

Optimized for recognizing individuals **without face masks**.

**Key Characteristics:**
- âŒ No filtering applied (optimal for clear faces)
- âœ… Faster processing
- âœ… Better accuracy for unmasked faces
- ğŸ“Š Hybrid features: LBP + Deep embeddings

**Best For:** Secure access systems, identification in controlled environments

**Quick Start:**
```bash
cd mobilenet_lbp_unmasked
python train_unmasked_simple.py
```

---

### 2. **Masked Pipeline** (`mobilenet_lbp_masked/`)

Specialized for recognizing individuals **wearing face masks**.

**Key Characteristics:**
- âœ… **Gaussian filtering** enabled (handles mask artifacts)
- âœ… **Mask detection** built-in
- âœ… Fine-tuned for masked scenarios
- ğŸ”§ Configurable: 20 epochs, batch size 16, LR 0.01

**Best For:** Medical facilities, public health surveillance, post-pandemic deployments

**Quick Start:**
```bash
cd mobilenet_lbp_masked
python train_masked_simple.py
```

---

### 3. **Both Scenarios Pipeline** (`mobilenet_lbp_both/`)

Unified solution for **mixed masked and unmasked** environments.

**Key Characteristics:**
- âœ… Handles both masked and unmasked faces
- âœ… Adaptive filtering (Gaussian or Median)
- âœ… Comprehensive feature extraction
- ğŸ¯ Cosine similarity identification
- ğŸ“ˆ Production-ready performance

**Best For:** Public spaces, airports, real-world deployments with variable mask usage

**Quick Start:**
```bash
cd mobilenet_lbp_both
python train.py --train_dir data/train
```

---

## ğŸ“¥ Installation

### Prerequisites

- **Python 3.8+**
- **CUDA 11.0+** (recommended for GPU support)
- **8GB+ RAM** (16GB recommended for fine-tuning)

### Step 1: Clone Repository

```bash
git clone https://github.com/yourusername/face-recognition-system.git
cd face-recognition-system
```

### Step 2: Install Dependencies

```bash
pip install -r requirements.txt
```

**Core Dependencies:**
- TensorFlow 2.10+
- OpenCV 4.5+
- NumPy 1.21+
- scikit-image
- scikit-learn
- PyYAML

### Step 3: Download Pre-trained Weights (Optional)

Some detectors may require pre-trained weights:
```bash
# YOLO weights (if using YOLO detector)
# Usually automatically downloaded on first use
```

---

## ğŸš€ Quick Start

### Using the Unmasked Pipeline

```bash
# Navigate to unmasked pipeline
cd mobilenet_lbp_unmasked

# Train on your unmasked dataset
python train_unmasked_simple.py

# Or with custom parameters
python train_unmasked.py \
    --train_dir "path/to/dataset" \
    --model_dir "models/my_model" \
    --detector_type yolo
```

### Using the Masked Pipeline

```bash
# Navigate to masked pipeline
cd mobilenet_lbp_masked

# Train on your masked dataset
python train_masked_simple.py

# With custom learning rate
python train_masked_simple.py --learning_rate 0.001
```

### Using the Both Pipeline

```bash
# Navigate to both pipeline
cd mobilenet_lbp_both

# Train on mixed dataset
python train.py \
    --train_dir data/train \
    --val_dir data/val \
    --filter_type gaussian \
    --detector_type yolo
```

---

## ğŸ“– Usage Guide

### Dataset Structure

All pipelines expect the following directory structure:

```
your_dataset/
â”œâ”€â”€ person_1/
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ person_2/
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ person_n/
    â””â”€â”€ ...
```

**Requirements:**
- Minimum 3-5 images per person
- Supported formats: JPG, PNG, JPEG
- Recommended: 256Ã—256 or larger

### Python API Usage

#### Basic Usage (Unmasked)

```python
from mobilenet_lbp_unmasked.src_unmasked.pipeline import FaceRecognitionPipeline

# Initialize
pipeline = FaceRecognitionPipeline(
    target_size=(256, 256),
    remove_bg=True,
    detector_type='yolo',
    similarity_threshold=0.55,
    embedding_dim=128
)

# Train
pipeline.train(train_dir='data/train', val_dir='data/val')

# Save
pipeline.save_pipeline('models/unmasked_model')

# Inference
result = pipeline.process_image(image_path='test.jpg')
if result['success']:
    for face in result['faces']:
        print(f"Person: {face['prediction']}")
        print(f"Confidence: {face['confidence']:.2%}")
```

#### Masked Pipeline Usage

```python
from mobilenet_lbp_masked.src_masked.pipeline import FaceRecognitionPipeline

# Initialize with filtering
pipeline = FaceRecognitionPipeline(
    target_size=(256, 256),
    remove_bg=False,              # Disable to save memory
    filter_type='gaussian',       # Enable filtering
    detector_type='yolo',
    similarity_threshold=0.55,
    embedding_dim=128
)

# Train with fine-tuning
pipeline.train(
    train_dir='data/train_masked',
    fine_tune_embedder=True,
    epochs=20,
    batch_size=16,
    learning_rate=0.01
)

# Save and use
pipeline.save_pipeline('models/masked_model')
result = pipeline.process_image(image_path='masked_face.jpg')

# Check mask status
for face in result['faces']:
    print(f"Person: {face['prediction']}")
    print(f"Masked: {face['is_masked']}")
    print(f"Confidence: {face['confidence']:.2%}")
```

#### Batch Processing

```python
# Process multiple images
image_paths = ['img1.jpg', 'img2.jpg', 'img3.jpg']
results = pipeline.process_batch(image_paths)

for result, image_path in zip(results, image_paths):
    print(f"\n{image_path}:")
    if result['success']:
        for face in result['faces']:
            print(f"  â†’ {face['prediction']} ({face['confidence']:.2%})")
```

---

## ğŸ“ Project Structure

### Unmasked Pipeline

```
mobilenet_lbp_unmasked/
â”œâ”€â”€ src_unmasked/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py           # Main pipeline orchestrator
â”‚   â”œâ”€â”€ preprocessing.py      # Image preprocessing
â”‚   â”œâ”€â”€ segmentation.py       # Face detection (YOLO/MTCNN/MediaPipe)
â”‚   â”œâ”€â”€ lbp_extractor.py      # LBP feature extraction
â”‚   â”œâ”€â”€ embedding.py          # MobileNetV2 embeddings
â”‚   â”œâ”€â”€ detector.py           # Cosine similarity identification
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ train_unmasked_simple.py  # Quick training script
â”œâ”€â”€ train_unmasked.py         # Full training with options
â”œâ”€â”€ example_usage_unmasked.py # Usage examples
â”œâ”€â”€ QUICKSTART_UNMASKED.md    # Quick reference
â””â”€â”€ eva.txt                   # Evaluation metrics
```

### Masked Pipeline

```
mobilenet_lbp_masked/
â”œâ”€â”€ src_masked/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py           # Pipeline with filtering
â”‚   â”œâ”€â”€ preprocessing.py      # Background removal
â”‚   â”œâ”€â”€ segmentation.py       # Face + mask detection
â”‚   â”œâ”€â”€ filtering.py          # Gaussian/Median filtering
â”‚   â”œâ”€â”€ lbp_extractor.py      # LBP features
â”‚   â”œâ”€â”€ embedding.py          # Deep embeddings
â”‚   â”œâ”€â”€ detector.py           # Similarity identification
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ train_masked_simple.py    # Quick training script
â”œâ”€â”€ yolov8n.pt                # YOLO model weights
â”œâ”€â”€ eva.txt                   # Evaluation results
â””â”€â”€ README.md
```

### Both Pipeline

```
mobilenet_lbp_both/
â”œâ”€â”€ preprocessing.py          # Preprocessing utilities
â”œâ”€â”€ segmentation.py           # Multi-scenario face detection
â”œâ”€â”€ filtering.py              # Flexible filtering
â”œâ”€â”€ lbp_extractor.py          # LBP extraction
â”œâ”€â”€ embedding.py              # Embeddings
â”œâ”€â”€ detector.py               # Cosine similarity
â”œâ”€â”€ pipeline.py               # Unified pipeline
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ inference.py              # Inference script
â”œâ”€â”€ test_model.py             # Testing utilities
â”œâ”€â”€ yolov8n.pt                # YOLO weights
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ Evaluation.md             # Performance metrics
```

---

## âš™ï¸ Configuration Options

### Common Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `target_size` | Tuple[int, int] | (256, 256) | Image dimensions (width, height) |
| `remove_bg` | bool | True | Enable background removal |
| `detector_type` | str | 'yolo' | Face detector: 'yolo', 'mtcnn', 'mediapipe' |
| `similarity_threshold` | float | 0.55 | Cosine similarity threshold (0-1) |
| `embedding_dim` | int | 128 | Embedding vector dimension |

### Masked-Specific Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `filter_type` | str | 'gaussian' | Filtering: 'gaussian' or 'median' |
| `fine_tune_embedder` | bool | True | Enable embedder fine-tuning |
| `epochs` | int | 20 | Training epochs |
| `batch_size` | int | 16 | Batch size |
| `learning_rate` | float | 0.01 | Learning rate |

### Training Options

```bash
# Unmasked
python train_unmasked.py \
    --train_dir "data/train" \
    --val_dir "data/val" \
    --model_dir "models/my_model" \
    --target_size 256 256 \
    --detector_type yolo \
    --embedding_dim 128 \
    --similarity_threshold 0.55

# Masked
python train_masked_simple.py \
    --learning_rate 0.01 \
    --epochs 20 \
    --batch_size 16 \
    --filter_type gaussian

# Both
python train.py \
    --train_dir "data/train" \
    --val_dir "data/val" \
    --filter_type gaussian \
    --detector_type yolo \
    --remove_bg True
```

---

## ğŸ§  Model Components

### 1. **Preprocessing Module**

**Functionality:**
- Background removal using semantic segmentation
- Image resizing to uniform dimensions
- Normalization and augmentation

**Output:** Preprocessed image ready for face detection

### 2. **Segmentation Module**

**Available Detectors:**

| Detector | Speed | Accuracy | Use Case |
|----------|-------|----------|----------|
| **YOLO** | âš¡âš¡âš¡ Fast | â­â­â­ High | Real-time applications |
| **MTCNN** | âš¡âš¡ Medium | â­â­â­â­ Very High | High-quality detection |
| **MediaPipe** | âš¡âš¡âš¡ Fast | â­â­ Good | Lightweight deployments |

**Output:** Face bounding boxes, mask/no-mask classification

### 3. **Filtering Module** (Masked Pipeline Only)

**Gaussian Filter:**
- Reduces noise while preserving edges
- Ideal for masked faces with compression artifacts
- Kernel size: 5Ã—5 (configurable)

**Median Filter:**
- Preserves edges while removing salt-and-pepper noise
- Alternative for extreme noise conditions

**Output:** Filtered face region ready for feature extraction

### 4. **Feature Extraction**

**LBP (Local Binary Pattern):**
- Texture descriptor capturing local patterns
- Fast computation, rotation-invariant
- 59-dimensional feature vector (uniform patterns)

**MobileNetV2 Embeddings:**
- Deep learning-based feature extraction
- Pre-trained on face recognition tasks
- 128-dimensional embedding (configurable)
- Fine-tunable for domain adaptation

**Output:** Hybrid feature vector (LBP + embeddings)

### 5. **Identification Module**

**Cosine Similarity Matching:**
- Compares feature vectors using cosine distance
- Threshold-based classification
- Unknown person detection

**Confidence Score:**
- Computed as: `1 - cosine_distance`
- Range: [0, 1] (higher = more confident)
- Default threshold: 0.55 (adjustable)

**Output:** Predicted person identity + confidence score

---

## ğŸ“Š Performance

### Accuracy Metrics

**Unmasked Pipeline:**
- Accuracy: ~95-98%
- Processing time: ~50-100ms per face
- Memory footprint: ~2-3GB

**Masked Pipeline:**
- Accuracy: ~90-95%
- Mask detection rate: ~98%
- Processing time: ~60-120ms per face (with filtering)
- Memory footprint: ~2-3GB

**Both Pipeline:**
- Mixed accuracy: ~92-96%
- Processing time: ~55-110ms per face
- Memory footprint: ~3-4GB

### Optimization Tips

1. **Batch Processing:** Process multiple images together for efficiency
2. **GPU Acceleration:** Enable CUDA for 5-10x speedup
3. **Model Caching:** Load models once, reuse for multiple inferences
4. **Parameter Tuning:** Adjust thresholds based on your use case

---

## ğŸ”§ Troubleshooting

### Common Issues

**Issue: "Out of memory" error**
```python
# Solution 1: Disable background removal
pipeline = FaceRecognitionPipeline(remove_bg=False)

# Solution 2: Reduce image size
pipeline = FaceRecognitionPipeline(target_size=(192, 192))

# Solution 3: Process in smaller batches
results = pipeline.process_batch(images[:10])  # Process 10 at a time
```

**Issue: Low accuracy on certain faces**
```python
# Solution 1: Adjust similarity threshold
pipeline = FaceRecognitionPipeline(similarity_threshold=0.5)  # More lenient

# Solution 2: Fine-tune on your dataset
pipeline.train(
    train_dir='your_data',
    fine_tune_embedder=True,
    epochs=30
)
```

**Issue: False positives (wrong person identified)**
```python
# Solution: Increase threshold
pipeline = FaceRecognitionPipeline(similarity_threshold=0.65)  # More strict
```

---

## ğŸ“ˆ Results & Benchmarks

### Evaluation Metrics

Detailed evaluation results are available in each pipeline folder:
- `unmasked/eva.txt` - Unmasked pipeline metrics
- `masked/eva.txt` - Masked pipeline metrics
- `both/Evaluation.md` - Mixed scenario results

### ROC Curves

Included ROC curve visualizations:
- `roc_unmasked.png`
- `roc_masked.png`
- `roc_both.png`

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Areas for Contribution

- [ ] Additional face detectors (DSFD, RetinaFace)
- [ ] Alternative embeddings (ArcFace, VGGFace2)
- [ ] Performance optimizations
- [ ] Docker containerization
- [ ] REST API wrapper
- [ ] Web UI dashboard

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the LICENSE file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Ahmed Adel**
- GitHub: [@ahmad1adel](https://github.com/ahmad1adel)
- Email: your.email@example.com

---

## ğŸ“š References & Resources

### Papers

- MobileNetV2: [Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)
- LBP Features: [Face Recognition with Local Binary Patterns](https://ieeexplore.ieee.org/document/1469340)
- Cosine Similarity: [Face Recognition via Centered Coordinate Coding](https://arxiv.org/abs/1003.0391)

### Documentation

- [TensorFlow Documentation](https://www.tensorflow.org/learn)
- [OpenCV Documentation](https://docs.opencv.org/)
- [scikit-image Documentation](https://scikit-image.org/)

### Related Projects

- [FaceNet](https://github.com/davidsandberg/facenet)
- [DeepFace](https://github.com/serengalp/deepface)
- [MTCNN](https://github.com/ipazc/mtcnn)

---

## âš ï¸ Disclaimer

This system is provided for educational and research purposes. Ensure compliance with local privacy laws and regulations when deploying facial recognition systems.

---

## ğŸ¯ Future Enhancements

- [ ] Real-time video stream processing
- [ ] Multi-GPU support
- [ ] Model quantization for edge devices
- [ ] REST API deployment
- [ ] Web dashboard for monitoring
- [ ] Advanced analytics and reporting
- [ ] Database integration for large-scale deployments

---

**Last Updated:** January 2, 2026  
**Version:** 2.0.0

